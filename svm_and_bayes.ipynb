{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['Type 2' 'Pre-Diabetes' 'No Diabetes' 'Gestational' 'Type 1']\n",
      "diabetes_stage\n",
      "Type 2          44916\n",
      "Pre-Diabetes    23740\n",
      "No Diabetes      6044\n",
      "Gestational       209\n",
      "Type 1             91\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "zip_path = \"./data_processed.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "    X_train = pd.read_csv(z.open('X_train_std.csv'))\n",
    "    Y_train = pd.read_csv(z.open('Y_train.csv'))\n",
    "    X_test  = pd.read_csv(z.open('X_test_std.csv'))\n",
    "    Y_test  = pd.read_csv(z.open('Y_test.csv'))\n",
    "\n",
    "unique_values = Y_train['diabetes_stage'].unique()\n",
    "print(\"Unique values:\", unique_values)\n",
    "print(Y_train['diabetes_stage'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['gender', 'ethnicity', 'education_level', 'income_level',\n",
      "       'employment_status', 'smoking_status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify categorical columns (dtype == object)\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "# Apply one-hot encoding only to categorical columns\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Ensure train and test have the same columns\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit on training labels and transform both train/test\n",
    "Y_train_encoded = le.fit_transform(Y_train.values.ravel())\n",
    "Y_test_encoded = le.transform(Y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "\n",
    "def run_grid_search_classification(model_pipeline, param_grid, X_train, y_train, X_test, y_test, cv=5, scoring='accuracy'):\n",
    "    \"\"\"\n",
    "    Run GridSearchCV for SVM or Naive Bayes classification.\n",
    "\n",
    "    Args:\n",
    "        model_pipeline : sklearn pipeline or estimator\n",
    "        param_grid : dict of parameters for GridSearchCV\n",
    "        X_train, y_train, X_test, y_test : training and test data\n",
    "        cv : number of cross-validation folds\n",
    "        scoring : metric for GridSearchCV ('accuracy', 'f1_macro', etc.)\n",
    "        doJaccard : only works if pipeline has a linear model with coef_ attribute\n",
    "\n",
    "    Returns:\n",
    "        best_model, best_params\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_pipeline,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scoring,\n",
    "        refit=True,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Fit GridSearch\n",
    "    grid_search.fit(X_train, y_train.ravel() if len(y_train.shape) > 1 else y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # CV results\n",
    "    cv_results = grid_search.cv_results_\n",
    "    best_index = grid_search.best_index_\n",
    "    mean_score = cv_results['mean_test_score'][best_index]\n",
    "    std_score = cv_results['std_test_score'][best_index]\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(\"\\nClassification report on test set:\\n\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(\"Best params:\", best_params)\n",
    "    print(f\"CV {scoring}: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} s\")\n",
    "\n",
    "    return best_model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Classification report on test set:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        69\n",
      "           1       0.41      0.64      0.50      1937\n",
      "           2       0.59      0.70      0.64      8105\n",
      "           3       0.00      0.00      0.00        31\n",
      "           4       0.91      0.75      0.82     14858\n",
      "\n",
      "    accuracy                           0.72     25000\n",
      "   macro avg       0.38      0.42      0.39     25000\n",
      "weighted avg       0.76      0.72      0.73     25000\n",
      "\n",
      "Best params: {'svc__C': 10, 'svc__gamma': 'scale', 'svc__kernel': 'rbf'}\n",
      "CV accuracy: 0.7205 ± 0.0041\n",
      "Test accuracy: 0.7205\n",
      "Elapsed time: 12064.20 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_svm = Pipeline([\n",
    "    ('svc', SVC(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid_svm = {\n",
    "    'svc__kernel': ['linear', 'rbf'],\n",
    "    'svc__C': [0.1, 1, 10],\n",
    "    'svc__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "best_svm, best_params_svm = run_grid_search_classification(\n",
    "    pipe_svm, param_grid_svm, X_train_encoded, Y_train_encoded, X_test_encoded, Y_test_encoded\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        69\n",
      "           1       0.41      0.64      0.50      1937\n",
      "           2       0.59      0.70      0.64      8105\n",
      "           3       0.00      0.00      0.00        31\n",
      "           4       0.91      0.75      0.82     14858\n",
      "\n",
      "    accuracy                           0.72     25000\n",
      "   macro avg       0.38      0.42      0.39     25000\n",
      "weighted avg       0.76      0.72      0.73     25000\n",
      "\n",
      "Test accuracy: 0.72052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the pipeline with fixed parameters (no grid search)\n",
    "pipe_svm = Pipeline([\n",
    "    ('svm', SVC(\n",
    "        kernel='rbf',\n",
    "        C=10,\n",
    "        gamma='scale',\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipe_svm.fit(X_train_encoded, Y_train_encoded)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipe_svm.predict(X_test_encoded)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(Y_test_encoded, y_pred))\n",
    "print(\"Test accuracy:\", accuracy_score(Y_test_encoded, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 762, in fit\n    self._count(X, Y)\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1037, in _count\n    check_non_negative(X, \"ComplementNB (input X)\")\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1824, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to ComplementNB (input X).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      3\u001b[39m pipe_nb = Pipeline([\n\u001b[32m      4\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mnb\u001b[39m\u001b[33m'\u001b[39m, ComplementNB(class_prior=\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m      5\u001b[39m ])\n\u001b[32m      7\u001b[39m param_grid_nb = {\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnb__alpha\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.1\u001b[39m, \u001b[32m0.5\u001b[39m, \u001b[32m1.0\u001b[39m, \u001b[32m2.0\u001b[39m, \u001b[32m5.0\u001b[39m],\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnb__fit_prior\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m],\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnb__norm\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m],\n\u001b[32m     11\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m best_nb, best_params_nb = \u001b[43mrun_grid_search_classification\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpipe_nb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid_nb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test_encoded\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mrun_grid_search_classification\u001b[39m\u001b[34m(model_pipeline, param_grid, X_train, y_train, X_test, y_test, cv, scoring)\u001b[39m\n\u001b[32m     26\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     27\u001b[39m     estimator=model_pipeline,\n\u001b[32m     28\u001b[39m     param_grid=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     verbose=\u001b[32m2\u001b[39m\n\u001b[32m     34\u001b[39m )\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Fit GridSearch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m best_model = grid_search.best_estimator_\n\u001b[32m     40\u001b[39m best_params = grid_search.best_params_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1028\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m   1026\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1031\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n100 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 762, in fit\n    self._count(X, Y)\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1037, in _count\n    check_non_negative(X, \"ComplementNB (input X)\")\n  File \"c:\\Users\\rylee\\anaconda3\\envs\\stats\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1824, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to ComplementNB (input X).\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "pipe_nb = Pipeline([\n",
    "    ('nb', ComplementNB(class_prior=None))\n",
    "])\n",
    "\n",
    "param_grid_nb = {\n",
    "    'nb__alpha': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    'nb__fit_prior': [True, False],\n",
    "    'nb__norm': [True, False],\n",
    "}\n",
    "\n",
    "\n",
    "best_nb, best_params_nb = run_grid_search_classification(\n",
    "    pipe_nb, param_grid_nb, X_train_encoded, Y_train_encoded, X_test_encoded, Y_test_encoded\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.99      0.01        69\n",
      "           1       0.48      0.26      0.34      1937\n",
      "           2       0.61      0.32      0.42      8105\n",
      "           3       0.01      0.06      0.01        31\n",
      "           4       0.84      0.48      0.61     14858\n",
      "\n",
      "    accuracy                           0.41     25000\n",
      "   macro avg       0.39      0.42      0.28     25000\n",
      "weighted avg       0.73      0.41      0.52     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_encoded, Y_train_encoded)  # use encoded labels\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(Y_test_encoded, y_pred))\n",
    "print(classification_report(Y_test_encoded, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
